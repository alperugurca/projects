{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--kRCYcp8uup"
      },
      "source": [
        "# Recommendation Systems with ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRPdUN1R8NuD",
        "outputId": "edd7798b-610e-470a-8520-9644cd0e4d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
            "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "RMSE: 1.0194\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1.0193536815834319"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from surprise import Dataset, KNNBasic, accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# load data\n",
        "data = Dataset.load_builtin(\"ml-100k\")\n",
        "\n",
        "# split data\n",
        "trainset, testset = train_test_split(data, test_size = 0.2, random_state = 42)\n",
        "\n",
        "# build model\n",
        "model_options = {\"name\": \"cosine\", \"user_based\": True}\n",
        "model = KNNBasic(sim_options = model_options)\n",
        "model.fit(trainset)\n",
        "\n",
        "#test model\n",
        "prediction = model.test(testset)\n",
        "accuracy.rmse(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udue4Jvc8qS_",
        "outputId": "214d0c74-4392-429d-a085-a980e625da2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "top 5 recommendation for user 2\n",
            "item id: 315, score: 4.350265065443496\n",
            "item id: 313, score: 4.274944015567098\n",
            "item id: 316, score: 4.250839405889038\n",
            "item id: 251, score: 4.228327504884321\n",
            "item id: 14, score: 4.1746992462879255\n"
          ]
        }
      ],
      "source": [
        "# recommendation system\n",
        "def get_top_n(predictions, n = 10):\n",
        "\n",
        "    top_n = {}\n",
        "\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        if not top_n.get(uid):\n",
        "            top_n[uid] = []\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n\n",
        "\n",
        "n = 5\n",
        "top_n = get_top_n(prediction, n)\n",
        "\n",
        "user_id = \"2\"\n",
        "print(f\"top {n} recommendation for user {user_id}\")\n",
        "for item_id, rating in top_n[user_id]:\n",
        "    print(f\"item id: {item_id}, score: {rating}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
