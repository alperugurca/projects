{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "# Define data paths\n",
    "DATA_PATH = '/kaggle/input/ml-zoomcamp-2024-competition'\n",
    "\n",
    "def load_and_check_data():\n",
    "    \"\"\"Load data and print basic information\"\"\"\n",
    "    # Load training data\n",
    "    sales_df = pd.read_csv(f'{DATA_PATH}/sales.csv')\n",
    "    \n",
    "    # Load and process test data\n",
    "    test_df = pd.read_csv(f'{DATA_PATH}/test.csv', sep=';')  # Use separator\n",
    "    \n",
    "    print(\"Sales DataFrame Info:\")\n",
    "    print(sales_df.info())\n",
    "    print(\"\\nSales DataFrame Head:\")\n",
    "    print(sales_df.head())\n",
    "    \n",
    "    print(\"\\nTest DataFrame Info:\")\n",
    "    print(test_df.info())\n",
    "    print(\"\\nTest DataFrame Head:\")\n",
    "    print(test_df.head())\n",
    "    \n",
    "    return sales_df, test_df\n",
    "\n",
    "def prepare_features(df, is_train=True):\n",
    "    \"\"\"Create features from the available data\"\"\"\n",
    "    if is_train:\n",
    "        # For training data\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "    else:\n",
    "        # For test data\n",
    "        df['date'] = pd.to_datetime(df['date'], format='%d.%m.%Y')\n",
    "    \n",
    "    # Create date-based features\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    \n",
    "    if is_train:\n",
    "        # Create lag features for training data\n",
    "        df['lag_1'] = df.groupby(['item_id', 'store_id'])['quantity'].shift(1)\n",
    "        df['lag_7'] = df.groupby(['item_id', 'store_id'])['quantity'].shift(7)\n",
    "        \n",
    "        # Create rolling mean features\n",
    "        df['rolling_mean_7'] = df.groupby(['item_id', 'store_id'])['quantity'].transform(\n",
    "            lambda x: x.rolling(window=7, min_periods=1).mean())\n",
    "        df['rolling_mean_30'] = df.groupby(['item_id', 'store_id'])['quantity'].transform(\n",
    "            lambda x: x.rolling(window=30, min_periods=1).mean())\n",
    "    else:\n",
    "        # For test data, initialize these columns with 0\n",
    "        df['lag_1'] = 0\n",
    "        df['lag_7'] = 0\n",
    "        df['rolling_mean_7'] = 0\n",
    "        df['rolling_mean_30'] = 0\n",
    "    \n",
    "    # Fill NaN values\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def prepare_training_data(df):\n",
    "    \"\"\"Prepare data for model training\"\"\"\n",
    "    # Select features for training\n",
    "    feature_columns = [\n",
    "        'year', 'month', 'day', 'day_of_week', 'is_weekend',\n",
    "        'lag_1', 'lag_7', 'rolling_mean_7', 'rolling_mean_30',\n",
    "        'store_id'  # Adding store_id as a feature\n",
    "    ]\n",
    "    \n",
    "    X = df[feature_columns]\n",
    "    y = df['quantity']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, feature_columns\n",
    "\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"Train XGBoost model\"\"\"\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=7,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Evaluate model performance using multiple metrics\"\"\"\n",
    "    metrics = {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'R2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def generate_submission(model, test_df, feature_columns):\n",
    "    \"\"\"Generate submission file\"\"\"\n",
    "    # Make predictions\n",
    "    test_features = test_df[feature_columns]\n",
    "    predictions = model.predict(test_features)\n",
    "    \n",
    "    # Create submission dataframe\n",
    "    submission = pd.DataFrame({\n",
    "        'row_id': test_df['row_id'],\n",
    "        'quantity': predictions\n",
    "    })\n",
    "    \n",
    "    # Save submission file\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission file created successfully!\")\n",
    "\n",
    "def main():\n",
    "    # Load and check data\n",
    "    print(\"Loading and checking data...\")\n",
    "    train_df, test_df = load_and_check_data()\n",
    "    \n",
    "    # Prepare features\n",
    "    print(\"Preparing features...\")\n",
    "    train_df = prepare_features(train_df, is_train=True)\n",
    "    test_df = prepare_features(test_df, is_train=False)\n",
    "    \n",
    "    # Prepare training data\n",
    "    print(\"Preparing training data...\")\n",
    "    X_train, X_test, y_train, y_test, feature_columns = prepare_training_data(train_df)\n",
    "    \n",
    "    # Train model\n",
    "    print(\"Training model...\")\n",
    "    model = train_model(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and evaluate\n",
    "    print(\"Evaluating model...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    metrics = evaluate_model(y_test, y_pred, \"XGBoost\")\n",
    "    \n",
    "    # Generate submission\n",
    "    print(\"Generating submission...\")\n",
    "    generate_submission(model, test_df, feature_columns)\n",
    "    \n",
    "    return model, metrics\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Define data paths\n",
    "DATA_PATH = '/kaggle/input/ml-zoomcamp-2024-competition'\n",
    "\n",
    "# Load the data first\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv(f'{DATA_PATH}/sales.csv')\n",
    "\n",
    "# Now perform EDA\n",
    "def perform_eda(sales_df):\n",
    "    \"\"\"Perform Exploratory Data Analysis\"\"\"\n",
    "    print(\"=== Basic Statistics ===\")\n",
    "    print(\"\\nDescriptive Statistics for Numerical Columns:\")\n",
    "    print(sales_df.describe())\n",
    "    \n",
    "    print(\"\\n=== Missing Values Analysis ===\")\n",
    "    missing_values = sales_df.isnull().sum()\n",
    "    print(missing_values[missing_values > 0])\n",
    "    \n",
    "    print(\"\\n=== Target Variable Analysis ===\")\n",
    "    print(\"\\nQuantity Statistics:\")\n",
    "    print(f\"Mean quantity: {sales_df['quantity'].mean():.2f}\")\n",
    "    print(f\"Median quantity: {sales_df['quantity'].median():.2f}\")\n",
    "    print(f\"Min quantity: {sales_df['quantity'].min():.2f}\")\n",
    "    print(f\"Max quantity: {sales_df['quantity'].max():.2f}\")\n",
    "    \n",
    "    # Time-based analysis\n",
    "    sales_df['date'] = pd.to_datetime(sales_df['date'])\n",
    "    print(\"\\n=== Temporal Analysis ===\")\n",
    "    monthly_sales = sales_df.groupby(sales_df['date'].dt.to_period('M'))['quantity'].sum()\n",
    "    print(\"\\nMonthly Sales Trends:\")\n",
    "    print(monthly_sales)\n",
    "    \n",
    "    # Store and Item Analysis\n",
    "    print(\"\\n=== Store Analysis ===\")\n",
    "    store_stats = sales_df.groupby('store_id')['quantity'].agg(['mean', 'count'])\n",
    "    print(\"\\nStore-wise Statistics:\")\n",
    "    print(store_stats)\n",
    "    \n",
    "    print(\"\\n=== Item Analysis ===\")\n",
    "    item_stats = sales_df.groupby('item_id')['quantity'].agg(['mean', 'count'])\n",
    "    print(\"\\nTop 5 Items by Average Quantity:\")\n",
    "    print(item_stats.sort_values('mean', ascending=False).head())\n",
    "    \n",
    "    # Feature Correlations\n",
    "    numeric_cols = sales_df.select_dtypes(include=[np.number]).columns\n",
    "    correlations = sales_df[numeric_cols].corr()\n",
    "    print(\"\\n=== Feature Correlations ===\")\n",
    "    print(correlations['quantity'].sort_values(ascending=False))\n",
    "\n",
    "    return {\n",
    "        'monthly_sales': monthly_sales,\n",
    "        'store_stats': store_stats,\n",
    "        'item_stats': item_stats,\n",
    "        'correlations': correlations\n",
    "    }\n",
    "\n",
    "# Perform EDA\n",
    "print(\"Performing EDA...\")\n",
    "eda_results = perform_eda(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
